{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14294490,"sourceType":"datasetVersion","datasetId":9124711}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\nfrom tqdm.auto import tqdm\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:07.632327Z","iopub.execute_input":"2025-12-26T10:41:07.632960Z","iopub.status.idle":"2025-12-26T10:41:24.574925Z","shell.execute_reply.started":"2025-12-26T10:41:07.632911Z","shell.execute_reply":"2025-12-26T10:41:24.574140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/labr-clean/labr_cleaned.csv')\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:24.576899Z","iopub.execute_input":"2025-12-26T10:41:24.577478Z","iopub.status.idle":"2025-12-26T10:41:26.398071Z","shell.execute_reply.started":"2025-12-26T10:41:24.577445Z","shell.execute_reply":"2025-12-26T10:41:26.397317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Create ground_truth: 1,2 -> 0, 3 -> 0.5, 4,5 -> 1\nrating_to_norm = {1: 0, 2: 0, 3: 0.5, 4: 1, 5: 1}\ndf[\"ground_truth\"] = df[\"rating\"].map(rating_to_norm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:26.399282Z","iopub.execute_input":"2025-12-26T10:41:26.399637Z","iopub.status.idle":"2025-12-26T10:41:26.413671Z","shell.execute_reply.started":"2025-12-26T10:41:26.399609Z","shell.execute_reply":"2025-12-26T10:41:26.412835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Prepare dataset for fine-tuning\nclass LABRSentimentDataset(Dataset):\n    def __init__(self, df, text_col=\"review_text_clean\", label_col=\"ground_truth\", tokenizer=None, max_len=256):\n        self.texts = df[text_col].astype(str).tolist()\n        self.labels = df[label_col].tolist()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n        item = {k: v.squeeze(0) for k, v in encoding.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:26.414875Z","iopub.execute_input":"2025-12-26T10:41:26.415219Z","iopub.status.idle":"2025-12-26T10:41:26.432319Z","shell.execute_reply.started":"2025-12-26T10:41:26.415179Z","shell.execute_reply":"2025-12-26T10:41:26.431330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Split data\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:26.434799Z","iopub.execute_input":"2025-12-26T10:41:26.435281Z","iopub.status.idle":"2025-12-26T10:41:26.490744Z","shell.execute_reply.started":"2025-12-26T10:41:26.435242Z","shell.execute_reply":"2025-12-26T10:41:26.489966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Initialize tokenizer and model\nmodel_name = \"CAMeL-Lab/bert-base-arabic-camelbert-da\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:26.491877Z","iopub.execute_input":"2025-12-26T10:41:26.492316Z","iopub.status.idle":"2025-12-26T10:41:54.021043Z","shell.execute_reply.started":"2025-12-26T10:41:26.492284Z","shell.execute_reply":"2025-12-26T10:41:54.019849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Create datasets and loaders\ntrain_ds = LABRSentimentDataset(train_df, tokenizer=tokenizer)\nval_ds = LABRSentimentDataset(val_df, tokenizer=tokenizer)\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:54.022375Z","iopub.execute_input":"2025-12-26T10:41:54.023152Z","iopub.status.idle":"2025-12-26T10:41:54.038526Z","shell.execute_reply.started":"2025-12-26T10:41:54.023119Z","shell.execute_reply":"2025-12-26T10:41:54.037238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Fine-tune model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # Use torch.optim.AdamW\nnum_training_steps = 3 * len(train_loader)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * num_training_steps),\n    num_training_steps=num_training_steps,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:54.040110Z","iopub.execute_input":"2025-12-26T10:41:54.040614Z","iopub.status.idle":"2025-12-26T10:41:54.133631Z","shell.execute_reply.started":"2025-12-26T10:41:54.040572Z","shell.execute_reply":"2025-12-26T10:41:54.132198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nfor epoch in range(3):\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/3\")\n    for batch in loop:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = criterion(outputs.logits.squeeze(), batch[\"labels\"])\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        loop.set_postfix(loss=loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:41:54.134963Z","iopub.execute_input":"2025-12-26T10:41:54.135359Z","iopub.status.idle":"2025-12-26T10:48:23.955384Z","shell.execute_reply.started":"2025-12-26T10:41:54.135313Z","shell.execute_reply":"2025-12-26T10:48:23.954172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 8. Predict sentiment for all reviews\nmodel.eval()\ndef predict_sentiment(texts, batch_size=32):\n    all_preds = []\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        enc = tokenizer(\n            batch_texts,\n            truncation=True,\n            padding=True,\n            max_length=256,\n            return_tensors=\"pt\"\n        )\n        enc = {k: v.to(device) for k, v in enc.items()}\n        with torch.no_grad():\n            outputs = model(**enc)\n            preds = outputs.logits.squeeze().cpu().tolist()\n            if isinstance(preds, float):\n                preds = [preds]\n            all_preds.extend(preds)\n    return all_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:48:23.956203Z","iopub.status.idle":"2025-12-26T10:48:23.956522Z","shell.execute_reply.started":"2025-12-26T10:48:23.956391Z","shell.execute_reply":"2025-12-26T10:48:23.956409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = predict_sentiment(df[\"review_text_clean\"].astype(str).tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:48:23.957871Z","iopub.status.idle":"2025-12-26T10:48:23.958186Z","shell.execute_reply.started":"2025-12-26T10:48:23.958045Z","shell.execute_reply":"2025-12-26T10:48:23.958064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 9. Convert predictions to 0, 0.5, or 1\ndef round_to_sentiment(score):\n    if score < 0.25:\n        return 0\n    elif score < 0.75:\n        return 0.5\n    else:\n        return 1\n\ndf[\"camel_sentiment\"] = [round_to_sentiment(p) for p in preds]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:48:23.959780Z","iopub.status.idle":"2025-12-26T10:48:23.960223Z","shell.execute_reply.started":"2025-12-26T10:48:23.959999Z","shell.execute_reply":"2025-12-26T10:48:23.960027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10. Save updated dataframe\ndf.to_csv(\"labr_balanced_with_sentiment.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T10:48:23.961918Z","iopub.status.idle":"2025-12-26T10:48:23.962420Z","shell.execute_reply.started":"2025-12-26T10:48:23.962204Z","shell.execute_reply":"2025-12-26T10:48:23.962231Z"}},"outputs":[],"execution_count":null}]}